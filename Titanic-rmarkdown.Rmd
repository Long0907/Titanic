---
title: "Titanic"
author: "Long Zheng"
date: "12/4/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

## __Use machine learning to create a model that predicts which passengers survived the Titanic shipwreck__


#required packages
```{r, include=FALSE}
library(tidyverse)
library(ROCit)
source("plot_resid_lev_logistic.R")
```

#load the trainning dataset and explore.
```{r}
train<- read_csv("dataset/train.csv")
```


```{r EDA}
#drop cabin column, because of too many missing data 687/891. 
train <- train[!colnames(train)=='Cabin']
# make sex and embarked as factor variables with levels
train<-
  train %>% 
  mutate(Sex.f = as.factor(Sex),
         Embarked.f = factor(Embarked))
#get an overview of the data
t1<-
train %>% 
  select(Survived,Pclass,Age,SibSp,Parch,Fare,Sex.f,Embarked.f) %>% 
  skimr::skim()
#too much missing data in cabin (687/891). 
t1 <- data.frame(t1)

# survival distribution  
hist(train$Survived)
# age
hist(train$Age,xlab = "Age",ylab = "count", main = "")
# sex
hist(train$Sex2,xlab = "Gender(male =1)",ylab = "count", main = "")
# fare
hist(train$Fare)
```

```{r}
train %>% 
  group_by(Embarked) %>% 
  summarise(age = mean(Age,na.rm = T),
            fare = mean(Fare,na.rm = T))

```

```{r}
# Access linearity
library(mfp)
mfp(Survived~fp(Age),family=binomial,data = train)
mfp(Survived~fp(Fare),family=binomial,data = train)
# cut fare variable 
train<-
  train %>% 
  mutate(fare_cut = quantile(Fare,))

# univariable analysis
univ_Pclass<-glm(Survived~Pclass, family = binomial, data = train)
summary(univ_Pclass)
univ_Age<-glm(Survived~Age, family = binomial, data = train)
summary(univ_Age)
univ_Sex<-glm(Survived~Sex, family = binomial, data = train)
summary(univ_Sex)
univ_SibSp<-glm(Survived~SibSp, family = binomial, data = train)
summary(univ_SibSp) # not statistic significant
univ_Parch<-glm(Survived~Parch, family = binomial, data = train)
summary(univ_Parch)
univ_Embarked.f<-glm(Survived~Embarked.f, family = binomial, data = train)
summary(univ_Embarked.f)
univ_Fare<-glm(Survived~Fare, family = binomial, data = train)
summary(univ_Fare)

#use glmulti to obtain a best model.
best_subset_att <-
  glmulti::glmulti(Survived~Age+factor(Pclass)+Sex.f+Fare+Parch+Embarked.f, data = train,level=1, family = binomial, crit="aicc", confsetsize=128)

best_model <- 
  summary(best_subset_att)$bestmodel %>% glm(., data = train, family = binomial)

glm(Survived~+factor(Pclass)+Sex.f+Age+SibSp,family = binomial,data = train) %>% summary()
# add interaction 
glm(Survived~1+factor(Pclass)+Sex.f+Age+SibSp,family = binomial,data = train) %>% summary()

#Assess godness of fit.
ResourceSelection::hoslem.test(best_model$y, fitted(best_model), g=20)

#Assess residual and leverage
plot_resid_lev_logistic(best_model)

# Classification
DescTools::Conf(best_model, pos = 1)

best_model.p <-
  tibble(
    pred_p = best_model$fitted.values,
    y = best_model$y
  )

best_model.p %>%
  ggplot(aes(x = pred_p)) + 
  facet_wrap(~y) +
  geom_histogram() +
  geom_vline(xintercept = .5, color = "red")

# Accuracy
best_model.roc <- 
  ROCit::measureit(score = best_model$fitted.values, 
                   class = best_model$y,
                   measure = c("ACC", "SENS", "SPEC"))

tibble(
  Cutoff = best_model.roc$Cutoff,
  ACC = best_model.roc$ACC
) %>%
ggplot(aes(x = Cutoff, y = ACC)) +
  geom_point() +
  geom_line()

# ROC Curve
tibble(
  Cutoff = best_model.roc$Cutoff,
  SENS = best_model.roc$SENS,
  SPEC = best_model.roc$SPEC
) %>%
  pivot_longer(., cols = c("SENS", "SPEC"), values_to = "value", names_to = "metric") %>%
  ggplot(aes(x = Cutoff, y = value, color = metric)) +
  geom_point() + 
  geom_line()

tibble(
  Cutoff = best_model.roc$Cutoff,
  SENS = best_model.roc$SENS,
  SPEC = best_model.roc$SPEC,
  SUM = SENS + SPEC
) %>%
  arrange(-SUM, -SENS, -SPEC)
  
roc_empirical <- 
  rocit(score = best_model$fitted.values, class = best_model$y)
plot(roc_empirical, YIndex = F)
roc_empirical
summary(roc_empirical)
ciAUC(roc_empirical)

OptimalCutpoints::optimal.cutpoints(X = "pred_p", status = "y", 
                  data = data.frame(best_model.p), 
                  methods = c("Youden", "MaxSpSe", "MaxProdSpSe"), tag.healthy = 0)


library(plotROC)
best_model.p %>%
  ggplot(aes(m = pred_p, d = y)) + 
  geom_roc(n.cuts=0,labels=FALSE) + 
  style_roc(theme = theme_grey, xlab = "1 - Specificity", ylab = "Sensitivity") +
  geom_abline(slope = 1, intercept = 0)


#######Model prediction
test <- read_csv("dataset/test.csv")

# make sex and embarked as factor variables with levels
test<-
  test %>% 
  mutate(Sex.f = as.factor(Sex),
         Embarked.f = factor(Embarked))
#get an overview of the data
test_prediction <- tibble(pred.test = predict(best_model, test, type = "response"))
test_prediction <-test_prediction %>% 
  mutate(Survived = if_else(pred.test>0.5, 1, 0),
         PassengerId = test$PassengerId)

submission <- 
  test_prediction %>% 
  select(PassengerId, Survived)

write.csv(submission, "Titanic-submission.csv", row.names = FALSE)

```


<<<<<<< HEAD
=======

>>>>>>> e8cb8a5ec472e9426e3627b920d889d758386d69


>>>>>>> fde28cf4d522e575f77733ca687e7f9061336f0d
```{r univariable analysis}
univ_embk<-glm(Survived~Embarked2, family = binomial, data = train)
summary(univ_embk)
univ_Pclass<-glm(Survived~Pclass, family = binomial, data = train)
summary(univ_Pclass)
```

